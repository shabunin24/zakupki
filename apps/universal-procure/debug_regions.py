#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent))

from parser.ru_nlq import NLQParser

def debug_regions():
    """–û—Ç–ª–∞–¥–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤"""
    
    print("üîç –û—Ç–ª–∞–¥–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤")
    print("=" * 60)
    
    parser = NLQParser()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    query = "–±—É–º–∞–≥–∞ –ê4 –æ—Ñ–∏—Å–Ω–∞—è –ú–æ—Å–∫–≤–∞ –¥–æ 200 —Ç—ã—Å —Ä—É–±"
    normalized = parser._normalize_text(query)
    lemmatized = parser._lemmatize_text(normalized)
    
    print(f"üìù –ó–∞–ø—Ä–æ—Å: {query}")
    print(f"üìù –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π: {normalized}")
    print(f"üìù –õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π: {lemmatized}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∏—Å–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
    print(f"\nüîç –ü–æ–∏—Å–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ:")
    region_matches_normalized = []
    
    for region_info in parser.regions_dict:
        canonical = region_info["canonical"]
        aliases = region_info["aliases"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        if canonical.lower() in normalized:
            match_length = len(canonical.lower())
            is_city = "–ì–æ—Ä–æ–¥" in canonical
            region_matches_normalized.append((canonical, match_length, is_city, "canonical"))
            print(f"   –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ: {canonical} (–¥–ª–∏–Ω–∞: {match_length}, –≥–æ—Ä–æ–¥: {is_city})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
        for alias in aliases:
            if alias.lower() in normalized:
                match_length = len(alias.lower())
                is_city = "–ì–æ—Ä–æ–¥" in canonical
                region_matches_normalized.append((canonical, match_length, is_city, f"alias: {alias}"))
                print(f"   –°–∏–Ω–æ–Ω–∏–º: {alias} -> {canonical} (–¥–ª–∏–Ω–∞: {match_length}, –≥–æ—Ä–æ–¥: {is_city})")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∏—Å–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
    print(f"\nüîç –ü–æ–∏—Å–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ:")
    region_matches_lemmatized = []
    
    for region_info in parser.regions_dict:
        canonical = region_info["canonical"]
        aliases = region_info["aliases"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        if canonical.lower() in lemmatized:
            match_length = len(canonical.lower())
            is_city = "–ì–æ—Ä–æ–¥" in canonical
            region_matches_lemmatized.append((canonical, match_length, is_city, "canonical"))
            print(f"   –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ: {canonical} (–¥–ª–∏–Ω–∞: {match_length}, –≥–æ—Ä–æ–¥: {is_city})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
        for alias in aliases:
            if alias.lower() in lemmatized:
                match_length = len(alias.lower())
                is_city = "–ì–æ—Ä–æ–¥" in canonical
                region_matches_lemmatized.append((canonical, match_length, is_city, f"alias: {alias}"))
                print(f"   –°–∏–Ω–æ–Ω–∏–º: {alias} -> {canonical} (–¥–ª–∏–Ω–∞: {match_length}, –≥–æ—Ä–æ–¥: {is_city})")
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
    if region_matches_normalized:
        region_matches_normalized.sort(key=lambda x: (x[2], x[1]), reverse=True)
        selected_normalized = region_matches_normalized[0][0]
        print(f"   üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–π —Ä–µ–≥–∏–æ–Ω: {selected_normalized}")
    else:
        print(f"   ‚ùå –†–µ–≥–∏–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
    if region_matches_lemmatized:
        region_matches_lemmatized.sort(key=lambda x: (x[2], x[1]), reverse=True)
        selected_lemmatized = region_matches_lemmatized[0][0]
        print(f"   üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–π —Ä–µ–≥–∏–æ–Ω: {selected_lemmatized}")
    else:
        print(f"   ‚ùå –†–µ–≥–∏–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

if __name__ == "__main__":
    debug_regions()
